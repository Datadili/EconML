---
title: "Problem set 5"
author: "Dili Maduabum, Joshua Bailey"
date: "2024-02-16"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r library/Data loading, include= FALSE, echo = FALSE}
#install.packages('fastDummies')
#install.packages('leaps')
library(fastDummies) #for dummy variables
library(glmnet)
library(glmnetUtils)
library(tidyverse) # for pipe operators
library(haven) #for importing dta datasets
library(gt)
library(fixest) #for fixed effects
library(glue) # glue
library(modelsummary)
library(leaps) #stepwise regression
#load the data 
films <- read_dta("data/films_day.dta")
#View(films)
```
## Problem 1
1... 10

## 11
**11.a** A movie should appear in the dataset at least 18 times. Each has a record for the weekend (Friday, Saturday and Sunday) from the opening weekend to at least 6 weekends later (for the ones kept). The ones dropped were not in theaters for more than 6 weekends.

**11.b**
```{r}
#keeping films that aren't dropped
films_used <- films |> 
  filter(dropped != 1)
```

**11.c**
```{r}
# day when 12 Rounds came in
round_12_date <- as.Date("2009-03-27")

# Define the number of days to add
days_before <- 17984 #number under 12 Rounds "date" column

# Days prior to the 
reference_date <- round_12_date - days_before + 1

# Print the new date
print(reference_date)
```
**11.d**
```{r}
films_used_d <- films_used |> 
  mutate(movie_date = as.Date(reference_date + date)) |> 
  #putting the release_date in the 4th column
  select(title, production_budget, release_yr,
         movie_date, sat_date, everything())

films_used_d[, c("title", "movie_date")]
```

**11.e**
```{r}
#first using sat_date to get the date for each saturday
films_used_date <- films_used_d |>
  #getting the day for saturday
  mutate(sat_day = reference_date + sat_date) |>
  mutate(sat_day_of_week = wday(sat_day, label = TRUE)) |>
  mutate(
    fri_dummy = ifelse(movie_date == sat_day - 1, 1, 0),
    sat_dummy = ifelse(movie_date == sat_day , 1, 0),
    #reasoning... there was no movie released on Sunday....
    sun_dummy = ifelse(movie_date == sat_day + 1, 1, 0) 
  ) |> arrange(title)

films_used_date[, c("title", "movie_date","sat_day" ,"fri_dummy", "sat_dummy", "sun_dummy")]
```
**11.f**
```{r}
#creating dummies for week using fastDummies
films_used_date <- films_used_date |>  
  arrange(title, sat_day) |> 
  group_by(title) |> 
  # Assign numeric labels to unique elements of sat_date within each title
  mutate(week = as.integer(factor(sat_date)))


#Now using fast dummies...
films_used_date <- dummy_cols(films_used_date, select_columns = 'week')
films_used_date[, c("title", "movie_date" ,"week_1", "week_2", "week_3")]
```

**11.g**
```{r 11.g}
#using the "Fast Dummies" library... to automatically create dummies for year
film <- dummy_cols(films_used_date, select_columns = 'release_yr')

film[, c("title", "release_yr", "release_yr_2009", "release_yr_2010")]
```
**11.h**
```{r warning=FALSE, message = FALSE}
#combine the weekends 
temp <- film |> 
 mutate(weekend = case_when(
   sat_dummy == 1 ~ "Saturday",
   fri_dummy == 1 ~ "Friday",
   sun_dummy == 1 ~ "Sunday",
 )) |> 
  group_by(week, weekend) |> 
  summarize(mean = mean(tickets, na.rm = TRUE))

temp |> 
  ggplot(aes(x = week, y = mean, color = as.factor(weekend))) +
  geom_point() +
  geom_line() +
  scale_color_manual(values = c("Saturday" = "#4682B4", 
                               "Friday" = "red", 
                               "Sunday" = "#8B008B")) +
  labs(color = "Weekend",
       y = "Tickets",
       x = "Week") +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 6)) +  # Set x-axis ticks
  scale_y_continuous(breaks = scales::pretty_breaks(n = 6)) +  # Set y-axis ticks
  theme_bw()
```

## 12
NOT NEEDED

## 13
```{r}
#subset colnames that have the hh in them
holiday <- str_subset(colnames(film), "hh")

#make the things in holiday "add"
holiday_dummy <- str_c(holiday, collapse = " + ")

#day of the week dummies
weekend_dummy <- str_c(str_subset(colnames(film), "dummy"), collapse = " + ")

#week of the year dummies
week_dummy <- str_c(str_subset(colnames(film), "week_"), collapse = " + ")

#year of the week dummy
year_dummy <- str_c(str_subset(colnames(film), "release_yr_"), collapse = " + ")

#combine
mod1 <- glue("tickets ~ {weekend_dummy} + {week_dummy} + {year_dummy} + {holiday_dummy}")

#fit a regression model
reg_mod1 <- lm(as.formula(mod1), data = film)


film <- film |> 
  mutate(pred_tickets = predict(reg_mod1, film)) |> 
  mutate(abnormal_viewership = tickets - pred_tickets)

film[, c("tickets","pred_tickets", "abnormal_viewership", "sat_day")]
```
## 14
```{r}
weather <- read_dta("data/weather_collapsed_day.dta")

#adding www to the column names
original_cols <- colnames(weather) 

# adding prefix using the paste 
colnames(weather) <- paste("www", original_cols, sep = "_") 

weather
```

```{r}
weather_film <- film |> 
  left_join(weather |> #all variables except the saturday variable
              select(-c("www_sat_date")),
            #combine on dates, automatically filters out dates that don't match
            by = c("movie_date" = "www_date"))

#test <- weather_film |> 
#  arrange(title) |> 
#  select(title, movie_date, sat_day, contains("www"))
```
## 15
```{r warning = FALSE}
# Select columns with names containing "www_"
www_columns <- str_subset(colnames(weather_film), "www_")

# Create a copy of the original dataframe
df <- weather_film 

# Define regression formula with dummy variables
regressors <-  glue("~ {weekend_dummy} + {week_dummy} + {year_dummy} + {holiday_dummy}")

# Iterate over columns with names containing "www_"
for (columns in www_columns) {
  # Construct regression formula
  model <- paste(columns, regressors)
  
  # Generate names for predicted values and residuals
  pred_name <- paste("pred", columns, sep = "_")
  resid_name <- paste("abnormal", columns, sep = "_")
  
  # Add predicted values and residuals to the dataframe
  df <- df |> 
      mutate(!!pred_name := predict(lm(as.formula(model), data = df), df)) |> 
    #residuals = column - predicted_value_for_column
      mutate(!!resid_name := eval(parse(text = columns)) - eval(parse(text = pred_name)))
}

#remove the predicted and original values, keeping only the residuals
new_weather <- df |> 
  select(-c(contains("pred_www"), starts_with("www")))
```

## 16
```{r warning=FALSE}
#combine
#fit a regression model
week_2_data <- new_weather |> 
  filter(week_2 == 1)

#using the same regression 
reg_mod2 <- lm(as.formula(mod1), data = week_2_data)


new_weather_film_wk2 <- week_2_data |> 
  mutate(pred_tickets_wk_2 = predict(reg_mod2, week_2_data)) |> 
  mutate(abnormal_viewership_wk_2 = tickets - pred_tickets_wk_2)


new_weather_film_wk2[, c("tickets", "pred_tickets_wk_2", "week_2", "abnormal_viewership_wk_2")]
```
## 17
```{r message = FALSE, warning=FALSE}
#Mak
#subsetting the data to just be week 1
week_1_data <- new_weather |> 
  filter(week_1 == 1)

#creating the "abnormal viewerships in week 1"------------
mod1 <- glue("tickets ~ {weekend_dummy} + {week_dummy} + {year_dummy} + {holiday_dummy}")

#fit a regression model
reg_mod1 <- lm(as.formula(mod1), data = week_1_data)

new_weather_film_wk1 <- week_1_data |> 
  mutate(pred_tickets_wk_1 = predict(reg_mod1, week_1_data)) |> 
  mutate(abnormal_viewership_wk1 = tickets - pred_tickets_wk_1)

```

**17.a**  OLS;
```{r}
abnormal_weather_wk1_names <-
  str_subset(colnames(new_weather_film_wk1), "abnormal_www")

abnormal_weather_wk1 <-
  str_c(abnormal_weather_wk1_names, collapse = "+")

ols_glue <- glue("abnormal_viewership_wk1 ~ {abnormal_weather_wk1}")
ols_mod <- lm(as.formula(ols_glue),
     new_weather_film_wk1)

#modelsummary(list(ols_mod), output = "gt")
```
**17.b** 
```{r forward ,warning= FALSE, message= FALSE}
#subset the data to include the variables of interest
leaps_data <- new_weather_film_wk1 |> 
  select(c(abnormal_viewership_wk1, all_of(abnormal_weather_wk1_names)))

forward <- regsubsets(abnormal_viewership_wk1 ~ ., 
           data = leaps_data, method = "forward")

# Get summary of the models
summary_forward <- summary(forward)

# Find the index of the model with the highest R-squared Adjusted
best_model_index_fwd <- which.max(summary_forward$adjr2) #9th model has the highest

# Get the names of predictors (coef) in the best model (9), without the intercept([-1])
best_adjr_predictors <- names(coef(forward, id = best_model_index_fwd)[-1])

# Print the selected predictors and the corresponding R-squared Adjusted value
best_adjr_predictors

#running regressions based on the model from foward (adj R^2)
regs_fwd <- str_c(best_adjr_predictors, collapse = " + ")

fwd_glue <- glue("abnormal_viewership_wk1 ~ {regs_fwd}")

fwd_mod <- lm(as.formula(fwd_glue), data = new_weather_film_wk1)

```
**17.c**
```{r}
#only show the last steps (trace = 0)
backward <- step(ols_mod, direction = "backward",trace=0)
best_bkwd_predictors <- names(coefficients(backward)[-1])

best_bkwd_predictors

#running regressions based on the model from backward
regs_bkwd <- str_c(best_bkwd_predictors, collapse = " + ")

bkwd_glue <- glue("abnormal_viewership_wk1 ~ {regs_bkwd}")

bkwd_mod <- lm(as.formula(bkwd_glue), data = new_weather_film_wk1)
```
**17.d**
\textit{i}
```{r}
ridge_mod <- cv.glmnet(
  x = as.matrix(new_weather_film_wk1 |>
                select(all_of(abnormal_weather_wk1_names))),
  y = new_weather_film_wk1 |>
    pull(abnormal_viewership_wk1), #pull gets the numeric values
  alpha = 0, # Ridge penalty
  nfolds = 5 # 5 fold cross validation
)

#lambda that minimizes the cross validation error
nfold_ridge <- ridge_mod$lambda.min

coefs_nfold_ridge <- coef(ridge_mod, s = nfold_ridge)

```
\textit{ii}
```{r}
# Find lambda within 1 standard deviation of the minimum lambda (storind estimates for now. Will predict with model later)
nfold_ridge_1se <- ridge_mod$lambda.1se

coefs_nfold_ridge_1se <- coef(ridge_mod, s = nfold_ridge_1se)
```
**17.e**
\textit{i}
```{r}
lasso_mod <- cv.glmnet(
  x = as.matrix(new_weather_film_wk1 |>
                select(all_of(abnormal_weather_wk1_names))),
  y = new_weather_film_wk1 |>
    pull(abnormal_viewership_wk1), #pull gets the numeric values
  alpha = 1, # Lasso penalty
  nfolds = 5 # 5 fold cross validation
)

#lambda that minimizes the cross validation error
nfold_lasso = lasso_mod$lambda.min
```
\textit{ii}
```{r}
# Find lambda within 1 standard deviation of the minimum lambda
nfold_lasso_1se <- lasso_mod$lambda.1se
```
\textit{iii}







## 21
```{r message=FALSE}
#movies <- read_csv("data/movie_lens_20m/movie.csv")
#ratings <- read_csv("data/movie_lens_20m/rating.csv")
```


